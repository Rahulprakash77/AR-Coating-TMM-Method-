{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d72d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import gymnasium\n",
    "from gymnasium import spaces\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d1a07f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gymnasium' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMultilayerthinfilm\u001b[39;00m(gymnasium\u001b[38;5;241m.\u001b[39mEnv):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[0;32m      3\u001b[0m                  N: np\u001b[38;5;241m.\u001b[39marray, \n\u001b[0;32m      4\u001b[0m                  maximum_layers: \u001b[38;5;28mint\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m                  min_thickness: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10e-9\u001b[39m, \n\u001b[0;32m     11\u001b[0m                  work_path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m        Parameters:\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m        -----------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m            Path to the working directory, e.g., to save images\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gymnasium' is not defined"
     ]
    }
   ],
   "source": [
    "class Multilayerthinfilm(gymnasium.Env):\n",
    "    def __init__(self, \n",
    "                 N: np.array, \n",
    "                 maximum_layers: int, \n",
    "                 target: dict, \n",
    "                 weights: np.array = None, \n",
    "                 normalization: bool = True, \n",
    "                 sparse_reward: bool = True, \n",
    "                 max_thickness: float = 150e-9, \n",
    "                 min_thickness: float = 10e-9, \n",
    "                 work_path: str = '') -> None:\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        N : np.array of shape [M]\n",
    "            where M is the number of available materials\n",
    "        maximum_layers : integer\n",
    "            maximum_layers defines the maximum number of layers to stack\n",
    "        target : dictionary\n",
    "            with keys 'spectrum' and 'target'\n",
    "            target['spectrum'] holds the spectrum [m] under consideration and is of shape S\n",
    "            target['target'] holds the target reflectivity of a MLTF and is of shape S\n",
    "        weights : np.array of same shape S\n",
    "            This array allows you to steer the pixels' relative influence on the optimization/reward\n",
    "        normalization : bool\n",
    "            Determines whether to exponentially transform the reward or not (Look publication for details)\n",
    "        sparse_reward : bool\n",
    "            Determines whether to simulate and reward each intermediate stack or only the final stack\n",
    "        max_thickness : float\n",
    "            Determines the maximum layer thickness in meters.\n",
    "        min_thickness : float\n",
    "            Determines the minimum layer thickness in meters.\n",
    "        work_path : str\n",
    "            Path to the working directory, e.g., to save images\n",
    "        \"\"\"\n",
    "\n",
    "        self.N = N\n",
    "        self.maximum_layers = maximum_layers\n",
    "        # target-related:\n",
    "        # wavelength range\n",
    "        self.wl = target['spectrum']\n",
    "        # desired value for reflectivity (pixel-wise)\n",
    "        self.target = target['target']\n",
    "        if weights is None:\n",
    "            self.weights = np.ones_like(self.target)\n",
    "        else:\n",
    "            self.weights = weights\n",
    "            assert weights.shape[0] == self.target.shape[0], 'Shape of weights and target must coincide!'\n",
    "            assert np.all(weights >= 0), 'Weights are supposed to be non-negative!'\n",
    "            if np.all(weights == 0):\n",
    "                self.weights = np.ones_like(self.target)\n",
    "                print('All weights were zero -> if nothing is important quit optimization; we set each weight to one for you ;)...')\n",
    "        self.weights = self.weights / np.max(self.weights)\n",
    "\n",
    "        self.work_path = work_path\n",
    "        # borders for thicknesses:\n",
    "        self.max_thickness = max_thickness\n",
    "        self.min_thickness = min_thickness\n",
    "\n",
    "        # initialization for some attributes:\n",
    "        self.number_of_materials = N.shape[0]\n",
    "        self.simulation = np.nan * np.zeros_like(self.target)\n",
    "        self.reward = None\n",
    "        self.old_reward = None\n",
    "        self._reward_track = []\n",
    "        self.layers = []\n",
    "        self._initial_nmb_layers = 0\n",
    "\n",
    "        self.n = []\n",
    "        self.d = []\n",
    "        self.f = None\n",
    "        self.axs = None\n",
    "        # OpenAI/Gym related settings:\n",
    "        # action space:\n",
    "        space_list = [spaces.Discrete((self.number_of_materials + 1))]\n",
    "        for space in range(self.number_of_materials + 1):\n",
    "            space_list.append(spaces.Box(low=0, high=1, shape=(1,)))\n",
    "        self.action_space = spaces.Tuple(space_list)\n",
    "\n",
    "        # simulation state space:\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=((self.number_of_materials + 1) * maximum_layers, ), dtype=np.float64)\n",
    "\n",
    "        \n",
    "    def set_cladding(self):\n",
    "        \n",
    "        self.n_substrate = np.ones((1, self.wl.shape[0]))\n",
    "        self.d_substrate = np.array([np.inf]).squeeze()\n",
    "        self.n_ambient = np.ones((1, self.wl.shape[0]))\n",
    "        self.d_ambient = np.array([np.inf]).squeeze()\n",
    "        print('--- cladding set to default values ---')\n",
    "        if np.iscomplex(self.n_substrate[0, :]).any():\n",
    "            self.n_substrate[0, :] = np.real(self.n_substrate[0, :])\n",
    "            print('n_substrate must feature real-valued refractive indices in the first layer for computational/physical reasons (TMM); adopted via np.real()')\n",
    "        if np.iscomplex(self.n_ambient[-1, :]).any():\n",
    "            self.n_ambient[-1, :] = np.real(self.n_ambient[-1, :])\n",
    "            print('n_ambient must feature real-valued refractive indices in the last layer for computational/physical reasons (TMM); adopted via np.real()')\n",
    "        assert not np.iscomplex(self.n_substrate[0, :]).any(), 'n_substrate must feature real-valued refractive indices in the first layer for computational/physical reasons (TMM)..'\n",
    "        assert not np.iscomplex(self.n_ambient[-1, :]).any(), 'n_ambient must feature real-valued refractive indices in the last layer for computational/physical reasons (TMM)..'\n",
    "        self.d_substrate = self.d_substrate.reshape(-1, 1)\n",
    "        self.d_ambient = self.d_ambient.reshape(-1, 1)\n",
    "        print('cladding set....')\n",
    "        \n",
    "        \n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        \"\"\"\n",
    "        This method implements the conduction of an action in the environment. Namely, to stack a layer of a\n",
    "        particular thickness on top of an existing stack.\n",
    "\n",
    "        Args:\n",
    "            action: np.array of shape [2]\n",
    "                action[0 holds the material chosen by the agent as an integer value. Note that 0 leads to\n",
    "                termination of stacking. action[1] is a float between 0 and 1 and encodes the assigned thickness.\n",
    "\n",
    "        Returns:\n",
    "            observation: np.array\n",
    "                The new state of the environment after taking the action.\n",
    "            reward: float\n",
    "                The reward obtained from the action.\n",
    "            done: bool\n",
    "                A flag that determines whether the episode is done or not.\n",
    "            info: dict\n",
    "                Additional information (empty in this case).\n",
    "        \"\"\"\n",
    "\n",
    "        done = False\n",
    "        self.old_reward = self.reward\n",
    "\n",
    "        if action[0] == 0 or len(self.layers) >= self.maximum_layers:\n",
    "            done = True\n",
    "        else:\n",
    "            self.layers.append(int(action[0]))\n",
    "            n_layer = self.N[int(action[0] - 1), :].reshape(1, -1)\n",
    "            d_layer = self.denormalize_thickness(action[1])\n",
    "            self.n.append(n_layer)\n",
    "            self.d.append(d_layer)\n",
    "\n",
    "        cladded_n, cladded_d = self.stack_layers()\n",
    "        self.simulation = self.simulate(cladded_n, cladded_d)\n",
    "        self.reward = 0\n",
    "\n",
    "        if done or not self.sparse_reward:\n",
    "            self.reward, mse = self.reward_func(self.simulation, self.target, self.weights, self.baseline_mse, self.normalization)\n",
    "            if done:\n",
    "                self._reward_track.append(mse)  # track reward to compute baseline\n",
    "\n",
    "        if np.all(np.isnan(self.simulation)):\n",
    "            print('All simulated values in TMM are NaN!')\n",
    "\n",
    "        observation = [self.simulation, self.n, self.d, self.one_hot_layer_status()]\n",
    "        handback_reward = self.reward\n",
    "\n",
    "        return observation, handback_reward, done, {}\n",
    "    \n",
    "    def one_hot_layer_status(self):\n",
    "        one_hot_vectors = []\n",
    "        for layer in range(self.maximum_layers):\n",
    "            one_hot_vector = np.zeros((self.number_of_materials + 1))\n",
    "            if layer < len(self.layers):\n",
    "                one_hot_vector[int(self.layers[layer])] = 1 * self.normalize_thickness(self.d[layer])\n",
    "            one_hot_vectors.append(one_hot_vector)\n",
    "        one_hot_vectors = np.hstack(one_hot_vectors)\n",
    "        return one_hot_vectors\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        This method implements the reset of the environment to an initial state. However, to ease exploration,\n",
    "        a defined number of layers can be stacked before handing it to the agent.\n",
    "\n",
    "        Args:\n",
    "            self\n",
    "\n",
    "        Returns:\n",
    "            observation: np.array\n",
    "                The initial state of the environment after resetting.\n",
    "            reward: float\n",
    "                The initial reward.\n",
    "            done: bool\n",
    "                A flag that determines whether the episode is done or not (empty list in this case).\n",
    "            info: dict\n",
    "                Additional information (empty in this case).\n",
    "        \"\"\"\n",
    "        self.layers = []\n",
    "        self.n = []\n",
    "        self.d = []\n",
    "\n",
    "        if self._initial_nmb_layers > 0:\n",
    "            num_layers = random.randint(1, self._initial_nmb_layers - 1)\n",
    "            for _ in range(num_layers):\n",
    "                rnd_material_idx = random.randint(0, self.number_of_materials - 1)\n",
    "                rnd_material_d = random.uniform(0, 1)\n",
    "                self.layers.append(rnd_material_idx + 1)\n",
    "                n_layer = self.N[rnd_material_idx].reshape(1, -1)\n",
    "                d_layer = (self.max_thickness - self.min_thickness) * rnd_material_d + self.min_thickness\n",
    "                self.n.append(n_layer)\n",
    "                self.d.append(d_layer)\n",
    "\n",
    "        cladded_n, cladded_d = self.stack_layers()\n",
    "        self.simulation = self.simulate(cladded_n, cladded_d)\n",
    "\n",
    "        self.reward = 0\n",
    "        if not self.sparse_reward:\n",
    "            self.reward, _ = self.reward_func(self.simulation, self.target, self.weights, self.baseline_mse, self.normalization)\n",
    "\n",
    "        one_hot_status = self.one_hot_layer_status()\n",
    "\n",
    "        return [self.simulation, self.n, self.d, one_hot_status], self.reward, False, {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "\n",
    "    def render_target(self):\n",
    "        assert self.wl.shape[0] > 1, 'No rendering for a single wavelength!'\n",
    "\n",
    "        f_target, axs_target = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "        xaxis = np.linspace(0, self.wl.shape[0], 10, dtype=int)\n",
    "        xtickslabels = np.linspace(np.min(self.wl * 10 ** 9), np.max(self.wl * 10 ** 9), 10, dtype=int)\n",
    "\n",
    "        # Target\n",
    "        plt.sca(axs_target[0])\n",
    "        plt.plot(self.target.squeeze())\n",
    "        plt.xticks(xaxis, xtickslabels)\n",
    "        plt.xlabel('Wavelength [nm]')\n",
    "        plt.ylabel(self.mode + ' [1]')\n",
    "        plt.ylim([0, 1.05])\n",
    "        plt.title('Target')\n",
    "\n",
    "        # Weights\n",
    "        plt.sca(axs_target[1])\n",
    "        plt.plot(self.weights.squeeze())\n",
    "        plt.xticks(xaxis, xtickslabels)\n",
    "        plt.xlabel('Wavelength [nm]')\n",
    "        plt.ylabel('Weight [1]')\n",
    "        plt.ylim([0, 1.05 * np.max(self.weights)])\n",
    "        plt.title('Weights')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show(block=False)\n",
    "        plt.pause(0.1)\n",
    "\n",
    "        return [f_target, axs_target]\n",
    "\n",
    "    \n",
    "    \n",
    "    def simulate(self, n, d):\n",
    "        \"\"\"\n",
    "        This method implements the simulation of the reflectivity of a particular stack. The TMM and its\n",
    "        parallelization is based on previous work of Alexander Luce.\n",
    "\n",
    "        Args:\n",
    "            n: np.array of shape [(Sub + L + Am) x S]\n",
    "                n holds the refractive indices of L stacked layers by the agent, including substrate and ambient.\n",
    "            d: np.array of shape Sub + L + Am\n",
    "                d holds the thicknesses in meters of the layers\n",
    "\n",
    "        Returns:\n",
    "            r: np.array of shape [D x S]\n",
    "                r holds the pixel-wise reflectivity values for the directions and wavelengths under consideration\n",
    "        \"\"\"\n",
    "        result_dicts = tmm('s', n, d, (np.pi/180)*self.angle, self.wl)\n",
    "        result_dictp = tmm('p', n, d, (np.pi/180)*self.angle, self.wl)\n",
    "        if self.mode == 'reflectivity':\n",
    "            rs = result_dicts['R']\n",
    "            rp = result_dictp['R']\n",
    "            r = (rs + rp) / 2\n",
    "            return r\n",
    "        else:\n",
    "            ts = result_dicts['T']\n",
    "            tp = result_dictp['T']\n",
    "            t = (ts + tp) / 2\n",
    "            return t\n",
    "\n",
    "        \n",
    "    def create_action(self, mat_number, thickness, is_normalized=True):\n",
    "        if not is_normalized:\n",
    "            normalized_thickness = (thickness - self.min_thickness) / (self.max_thickness - self.min_thickness)\n",
    "        else:\n",
    "            normalized_thickness = thickness\n",
    "        action = (mat_number, np.array([normalized_thickness]))\n",
    "        return action\n",
    "\n",
    "\n",
    "    def create_stack(self, material_list, thickness_list=None):\n",
    "        if thickness_list is not None:\n",
    "            t = np.array(thickness_list)\n",
    "        else:\n",
    "            t = np.empty(0)\n",
    "        n = []\n",
    "        for material in material_list:\n",
    "            n.append(self.N[material-1, :])\n",
    "        n = np.vstack(n)\n",
    "        dictionary = {'n': n, 'd': t}\n",
    "        return n, t, dictionary\n",
    "    \n",
    "    \n",
    "    def stack_layers(self, d_array=None, n_array=None):\n",
    "        \"\"\"\n",
    "        This method clads the stack suggested by the agent with the pre-defined cladding.\n",
    "        The returned arrays n, d describe a particular stack, it includes the cladding.\n",
    "        \"\"\"\n",
    "\n",
    "        if n_array is not None:\n",
    "            n_list = list(n_array)\n",
    "        else:\n",
    "            n_list = self.n\n",
    "        if d_array is not None:\n",
    "            d_list = list(d_array)\n",
    "        else:\n",
    "            d_list = self.d\n",
    "\n",
    "        if len(n_list) != 0:\n",
    "            cladded_n = np.vstack(n_list)\n",
    "            cladded_d = np.vstack(d_list).reshape(-1, 1)\n",
    "            cladded_n = np.vstack((self.n_substrate, cladded_n))\n",
    "            cladded_d = np.vstack((self.d_substrate, cladded_d))\n",
    "            cladded_n = np.vstack((cladded_n, self.n_ambient))\n",
    "            cladded_d = np.vstack((cladded_d, self.d_ambient))\n",
    "        else:\n",
    "            cladded_n = np.vstack((self.n_substrate, self.n_ambient))\n",
    "            cladded_d = np.vstack((self.d_substrate, self.d_ambient))\n",
    "        return cladded_n.squeeze(), cladded_d.squeeze()\n",
    "    \n",
    "    \n",
    "    def steps_made(self):\n",
    "        \"\"\"\n",
    "        Returns the number of steps made in the environment\n",
    "        \"\"\"\n",
    "        return len(self.layers)\n",
    "\n",
    "    def reset_reward_track(self):\n",
    "        \"\"\"\n",
    "        To reset private property _reward_track.\n",
    "        \"\"\"\n",
    "        self._reward_track = []\n",
    "\n",
    "    def set_initial_layers(self, nmb_of_initial_layers):\n",
    "        \"\"\"\n",
    "        Setter for the private property that specifies an initial number of layers during environment reset\n",
    "        \"\"\"\n",
    "        if nmb_of_initial_layers > self.maximum_layers:\n",
    "            raise ValueError(\"Initial number of layers already exceeds the total number of allowed layers!\")\n",
    "        self._initial_nmb_layers = nmb_of_initial_layers\n",
    "        \n",
    "        \n",
    "        \n",
    "            @property\n",
    "    def baseline_mse(self):\n",
    "        \"\"\"\n",
    "        Returns the baseline mse for reward computation/transformation (See publication for details)\n",
    "        \"\"\"\n",
    "        if len(self._reward_track) == 0:\n",
    "            return 0.4\n",
    "        else:\n",
    "            return 0.4  # You can update this with your desired baseline MSE value.\n",
    "\n",
    "    @property\n",
    "    def num_layers(self) -> float:\n",
    "        \"\"\"\n",
    "        Returns the explicit number of layers of a stack\n",
    "        \"\"\"\n",
    "        if len(self.layers) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            counter = 0\n",
    "            prev_layer = -1\n",
    "            for layer in self.layers:\n",
    "                if not layer == prev_layer:\n",
    "                    counter += 1\n",
    "                    prev_layer = layer\n",
    "            return counter\n",
    "\n",
    "    @staticmethod\n",
    "    def reward_func(reflectivity, target, weights=None, baseline_mse=1.0, normalization=False, low_reward=0.01, high_reward=1.0):\n",
    "        \"\"\"\n",
    "        An unconstrained reward computation based on the observed reflectivity and the given target.\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            weights = np.ones_like(target)\n",
    "        else:\n",
    "            assert np.all(weights >= 0), 'weights are supposed to be non-negative!'\n",
    "        temp = np.abs(reflectivity - target) * weights\n",
    "        temp[weights == 0] = np.nan\n",
    "        baseline_error = np.nanmean(temp)\n",
    "        if normalization:\n",
    "            assert low_reward > 0, 'low_rewards needs to be non-negative!'\n",
    "            highest_measureable_reward = high_reward\n",
    "            lowest_measureable_reward = low_reward  # > 0\n",
    "            a = highest_measureable_reward\n",
    "            b = np.log(lowest_measureable_reward / highest_measureable_reward) / baseline_mse\n",
    "            reward = a * np.exp(b * baseline_error)\n",
    "        else:\n",
    "            reward = np.exp(-baseline_error)\n",
    "\n",
    "        return reward, baseline_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4874b297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
